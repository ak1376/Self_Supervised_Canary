{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2d799b",
   "metadata": {},
   "source": [
    "# Synthetic Song Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00970938",
   "metadata": {},
   "source": [
    "One way to evaluate how feasible using contrastive self-supervised learning is on canary vocalizations, we can create synthetic canary song as a testbed. Real canary vocalizations are highly rich and complex, with canaries singing many different syllables that vary from phrase to phrase. Our goal in this notebook is to generate a much simpler (synthetic) canary song where we have complete control over the generative process. Therefore, all further ML evaluation on this synthetic song will be highly tractable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae8c043",
   "metadata": {},
   "source": [
    "To create synthetic canary song we will follow the methods from \"Freedom and Rules: The Acquisition and Reprogramming of a Bird's Learned Song\" by Gardner, Naef, and Nottebohm. In this paper, the authors train a juvenile canary to sing a unrealistic canary song and see how well the juvenile canary is able to imitate the song. We will adapt the methods to fit our purposes. The general process of synthetic song generation is as follows:\n",
    "1. Initialize 10 acoustic parameters that we will use to simulate each syllable's frequency throughout a particular phrase\n",
    "2. Create a signal from the fundamental frequency + harmonic frequencies\n",
    "3. Apply some filtering, enveloping, and normalization to the signal\n",
    "4. Plot a spectrogram of the resulting song\n",
    "\n",
    "Details on the acoustic parameters and specific steps of song generation can be found in the supplemental methods of the aforementioned paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ac345",
   "metadata": {},
   "source": [
    "## Tutorial Simulating One Song"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d45b99e",
   "metadata": {},
   "source": [
    "### Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "541ade4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AnanyaKapoor/.conda/envs/Canary_Deep_Learning/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.signal as signal\n",
    "import sounddevice as sd  \n",
    "from scipy.io.wavfile import write\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import umap\n",
    "import os \n",
    "\n",
    "# Parameters we set\n",
    "num_spec = 1\n",
    "window_size = 100\n",
    "stride = 10\n",
    "sampling_freq = 44100\n",
    "\n",
    "\n",
    "folderpath = '/Users/ananyakapoor/Dropbox (University of Oregon)/Kapoor_Ananya/01_Projects/01_b_Canary_SSL/Canary_SSL_Repo/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecb48cb",
   "metadata": {},
   "source": [
    "### Parameter Initialization for each distinct syllable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b9688f",
   "metadata": {},
   "source": [
    "Each syllable is defined by a set of 10 acoustic parameters (refer to Gardner et. al 2005's supplementary methods for the full list). To create our synthetic dataset, we will specify mean values for each acoustic parameter for each distinct syllable. Each repeat of that syllable will be some random variation along a hyperellipsoid defined by a specified radius. The smaller the radius, the more homogeneous the repeats of a syllable will look. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f1774",
   "metadata": {},
   "source": [
    "We will specify the number of syllables to simulate. A subset of them will be \"short syllables\" (duration between 30 and 90 ms) and the remaining subset will be \"long syllables\" (duration between 100 and 400 ms). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6140955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_phi_0 = (np.random.uniform(0, 2*np.pi, num_syllables)).reshape(1, num_syllables)\n",
    "mean_delta_phi = (np.random.uniform(-3*np.pi/2, 3*np.pi/2, num_syllables)).reshape(1, num_syllables) # In radians\n",
    "mean_B = (np.random.uniform(300, 500, num_syllables)).reshape(1, num_syllables) # In Hz\n",
    "mean_c = (np.random.uniform(40, 70, num_syllables)).reshape(1, num_syllables)\n",
    "mean_f_0 = (np.random.uniform(800, 1500, num_syllables)).reshape(1, num_syllables) # In Hz\n",
    "\n",
    "short_durations = np.random.uniform(30/1000, 90/1000, num_short)\n",
    "long_durations = np.random.uniform(200/1000, 500/1000, num_long)\n",
    "# short_repeats = np.random.randint(50, 100, num_short)\n",
    "# long_repeats = np.random.randint(3, 5, num_long)\n",
    "\n",
    "mean_T = np.concatenate((short_durations, long_durations))\n",
    "# num_repeats = np.concatenate((short_repeats, long_repeats))\n",
    "\n",
    "permutation = np.random.permutation(len(mean_T))\n",
    "\n",
    "mean_T = mean_T[permutation]\n",
    "mean_T.shape = (1, num_syllables)\n",
    "# num_repeats = num_repeats[permutation]\n",
    "\n",
    "mean_Z_1 = (np.random.uniform(0.88, 0.93, num_syllables)).reshape(1, num_syllables)\n",
    "mean_Z_2 = (np.random.uniform(0.88, 0.93, num_syllables)).reshape(1, num_syllables)\n",
    "mean_theta_1 = (np.random.uniform(0.01, np.pi/2, num_syllables)).reshape(1, num_syllables)\n",
    "mean_theta_2 = (np.random.uniform(0.01, np.pi/2, num_syllables)).reshape(1, num_syllables)\n",
    "\n",
    "# num_repeats = 50*np.ones((1, num_syllables)) # Simple example\n",
    "\n",
    "mean_matrix = np.concatenate((mean_phi_0, mean_delta_phi, mean_B, mean_c, mean_f_0, mean_T, mean_Z_1, mean_Z_2, mean_theta_1, mean_theta_2), axis = 0)\n",
    "\n",
    "# Let's find a random order of syllable phrases to simulate \n",
    "unique_syllables = np.arange(num_syllables)\n",
    "syllable_phrase_order = unique_syllables.copy()\n",
    "phrase_repeats = 5\n",
    "\n",
    "syllable_phrase_order_songs = np.zeros((num_songs, syllable_phrase_order.shape[0]))\n",
    "num_repeats_songs = np.zeros((num_songs, num_syllables*phrase_repeats))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f0dbb5",
   "metadata": {},
   "source": [
    "### Generating an order of syllable phrases that we will simulate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377467a",
   "metadata": {},
   "source": [
    "We can specify how many times to repeat each syllable phrase. Moreover, the syllable phrase repeats will occur in a random order in the song. We will also specify how many songs to simulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28e2897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/Users/ananyakapoor/Dropbox (University of Oregon)/Kapoor_Ananya/01_Projects/01_b_Canary_SSL/Canary_SSL_Repo/Song_0/' already exists.\n"
     ]
    }
   ],
   "source": [
    "num_songs = 1\n",
    "song_index = 0\n",
    "\n",
    "folderpath_song = f'{folderpath}Song_{song_index}/'\n",
    "if not os.path.exists(folderpath_song):\n",
    "    # Create the directory\n",
    "    os.makedirs(folderpath_song)\n",
    "    print(f\"Directory '{folderpath_song}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{folderpath_song}' already exists.\")\n",
    "\n",
    "\n",
    "np.random.shuffle(syllable_phrase_order) # ex: 0, 2, 1 means that we will simulate syllable 0 first, followed by 2 and then followed by 1\n",
    "syllable_phrase_order_songs[song_index,:] = syllable_phrase_order\n",
    "\n",
    "syllable_phrase_order_w_repeats = np.repeat(syllable_phrase_order, phrase_repeats) # Now add the number of phrase repeats \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505085d9",
   "metadata": {},
   "source": [
    "Specifying empty lists to store each syllable repeat's acoustic parameters. Also define some parameters for the Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9670d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_0_vector = []\n",
    "delta_phi_vector = []\n",
    "B_vector = []\n",
    "c_vector = []\n",
    "f_0_vector = []\n",
    "T_vector = []\n",
    "Z_1_vector = []\n",
    "Z_2_vector = []\n",
    "theta_1_vector = []\n",
    "theta_2_vector = []\n",
    "\n",
    "# Initializing empty arrays that will hold our signal wave, filtered wave, and enveloped wave\n",
    "\n",
    "total_signal_wave = np.array([])\n",
    "total_filtered = np.array([])\n",
    "total_envelope = np.array([])\n",
    "total_normalized_signal = np.array([])\n",
    "\n",
    "# Sample parameters\n",
    "window_duration_seconds = 0.02  # 40 ms window\n",
    "window_size = int(sampling_freq * window_duration_seconds)\n",
    "overlap_fraction = 0.9       # 90 percent overlap           \n",
    "overlap = int(window_size * overlap_fraction) \n",
    "\n",
    "low_frequency_check = 0 \n",
    "high_frequency_check = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b606ad",
   "metadata": {},
   "source": [
    "Within a phrase we will repeat the syllable as many times until we reach a total phrase duration that is at least 1.4 seconds. Specify empty lists that will store the number of syllable repeats within a phrase and the total phrase duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c1e928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repeats_list = []\n",
    "phrase_duration_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703fc591",
   "metadata": {},
   "source": [
    "### Creating the Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for syl in syllable_phrase_order_w_repeats:\n",
    "    # mu = mean_matrix[:,syl]\n",
    "    # mean_duration = mu[5]\n",
    "    # num_repeats = np.ceil(2 /mean_duration)\n",
    "    # num_repeats_list.append(num_repeats)\n",
    "\n",
    "    num_repeats = 0\n",
    "    phrase_duration = 0\n",
    "\n",
    "    while phrase_duration < 1.4:\n",
    "\n",
    "        # We are going to ensure that each simulated parameter is within 1% of the mean value for the parameter. This will result in syllables with very little within-syllable variability\n",
    "\n",
    "        # Draw acoustic parameters with respect to the mean vector corresponding to the syllable we are simulating\n",
    "        mu = mean_matrix[:,syl]\n",
    "\n",
    "        # Define the desired radius (strictly within 0.05 from the centroid)\n",
    "        radius = 0.025\n",
    "\n",
    "        # Number of random points to generate\n",
    "        num_points = 1\n",
    "\n",
    "        # Number of dimensions (size of the centroid array)\n",
    "        num_dimensions = mu.shape[0]\n",
    "\n",
    "        # Generate random directions (unit vectors) in num_dimensions-dimensional space\n",
    "        random_directions = np.random.randn(num_points, num_dimensions)\n",
    "        random_directions /= np.linalg.norm(random_directions, axis=1)[:, np.newaxis]\n",
    "\n",
    "        # Generate random distances within the desired radius for each dimension\n",
    "        random_distances = radius * np.random.rand(num_points) ** (1/num_dimensions)\n",
    "\n",
    "        # Calculate the final random points within the hypersphere\n",
    "        acoustic_params = mu + random_distances[:, np.newaxis] * random_directions\n",
    "        acoustic_params.shape = (10,)\n",
    "\n",
    "\n",
    "        # for param in np.arange(10):\n",
    "        #     sim_param = (np.random.uniform(mu[param] - mu[param]*0.05, mu[param]+mu[param]*0.05, 1))\n",
    "        #     acoustic_params = np.concatenate((acoustic_params, sim_param))\n",
    "\n",
    "        # acoustic_params = np.random.multivariate_normal(mean_matrix[:,syl], covariance_matrix[syl, :, :])\n",
    "\n",
    "        # tab = np.concatenate((mean_matrix[:,syl].reshape(10,1), acoustic_params.reshape(10,1)), axis = 1)\n",
    "        # if low_frequency_check == 1:\n",
    "        #     f_0 += 50\n",
    "        #     acoustic_params[4] = f_0 \n",
    "        # elif high_frequency_check == 1:\n",
    "        #     f_0 -= 50\n",
    "        #     acoustic_params[4] = f_0 \n",
    "\n",
    "\n",
    "\n",
    "        phi_0 = acoustic_params[0]\n",
    "        phi_0_vector.append(phi_0)\n",
    "\n",
    "        delta_phi = acoustic_params[1]\n",
    "        delta_phi_vector.append(delta_phi)\n",
    "\n",
    "        B = acoustic_params[2]\n",
    "        # B_vector.append(B)\n",
    "\n",
    "        c = acoustic_params[3]\n",
    "        c_vector.append(c)\n",
    "\n",
    "        f_0 = acoustic_params[4]\n",
    "        # f_0_vector.append(f_0)\n",
    "\n",
    "        T = acoustic_params[5]\n",
    "        T_vector.append(T)\n",
    "        # print(T)\n",
    "\n",
    "        Z_1 = acoustic_params[6]\n",
    "        Z_1_vector.append(Z_1)\n",
    "\n",
    "        Z_2 = acoustic_params[7]\n",
    "        Z_2_vector.append(Z_2)\n",
    "\n",
    "        theta_1 = acoustic_params[8]\n",
    "        theta_1_vector.append(theta_1)\n",
    "\n",
    "        theta_2 = acoustic_params[9]\n",
    "        theta_2_vector.append(theta_2)\n",
    "\n",
    "        # Let's create a table where we have the sampled acoustic parameters plotted against the mean acoustic parameters\n",
    "        tab = np.concatenate((mean_matrix[:,syl].reshape(10,1), acoustic_params.reshape(10,1)), axis = 1)\n",
    "\n",
    "        num_samples = int((T)*sampling_freq)\n",
    "        t = np.linspace(0, ((T)), num_samples) \n",
    "\n",
    "        # Calculate the fundamental frequency across time\n",
    "        f = f_0 + B*np.cos(phi_0 + delta_phi*t/T)\n",
    "\n",
    "        syllable_labels = np.repeat(syl, t.shape[0])\n",
    "        labels_per_sample = np.concatenate((labels_per_sample, syllable_labels))\n",
    "\n",
    "\n",
    "        while np.min(f)<700:\n",
    "            low_frequency_check = 1\n",
    "            f_0+=50\n",
    "            B -=20\n",
    "            f = f_0 + B*np.cos(phi_0 + delta_phi*t/T)\n",
    "\n",
    "        while np.max(f)>3000:\n",
    "            high_frequency_check == 1\n",
    "            f_0-=50\n",
    "            B-=20\n",
    "            f = f_0 + B*np.cos(phi_0 + delta_phi*t/T)\n",
    "\n",
    "        # if np.min(f)<700:\n",
    "        #     low_frequency_check = 1\n",
    "        #     f_0+=50\n",
    "        #     B-=20\n",
    "        # else:\n",
    "        #     low_frequency_check = 0\n",
    "\n",
    "        # if np.max(f)>3000:\n",
    "        #     high_frequency_check = 1\n",
    "        #     f_0-=50\n",
    "        #     B-=20\n",
    "        # else:\n",
    "        #     high_frequency_check = 0\n",
    "\n",
    "        # if (low_frequency_check ==1) or (high_frequency_check == 1):\n",
    "        #     # Recalculate the fundamental frequency across time with the new f_0 and B values\n",
    "        #     f = f_0 + B*np.cos(phi_0 + delta_phi*t/T)\n",
    "\n",
    "\n",
    "        f_0_vector.append(f_0)\n",
    "        B_vector.append(B)\n",
    "        # It's the B*np.cos(phi_0_values + delta_phi_values*t/T) that gives the fundamental frequency its wavy shape. f_0 just shifts it up\n",
    "\n",
    "        #     # Now let's calculate the harmonics \n",
    "        num_harmonics = 12\n",
    "        theta_arr = np.zeros((num_harmonics, t.shape[0]))\n",
    "        for k in np.arange(num_harmonics):\n",
    "            # val = 2*np.pi*(k+1)*f.reshape(f.shape[0],)\n",
    "            val = 2*np.pi*(k+1)*f_0*t + (2*np.pi*(k+1)*B*T/(delta_phi))*(np.sin((phi_0)+(delta_phi)/T*t) - np.sin((phi_0)))\n",
    "            theta_arr[k, :] = val\n",
    "\n",
    "        ## coefficients\n",
    "\n",
    "        A_list = [1]\n",
    "        for k in np.arange(2, (num_harmonics + 1)):\n",
    "            coef = 1/(1+c*2**(k-1))\n",
    "            # coef = 1\n",
    "            A_list.append(coef)\n",
    "\n",
    "        #     # Raw signal\n",
    "\n",
    "        s_t_arr = np.zeros_like(t)\n",
    "\n",
    "        for k in np.arange(len(A_list)):\n",
    "            signal_val = A_list[k]*np.sin(theta_arr[k,:])\n",
    "            s_t_arr += signal_val\n",
    "\n",
    "\n",
    "        total_signal_wave = np.concatenate((total_signal_wave, s_t_arr))\n",
    "\n",
    "        #     # Filtered signal\n",
    "\n",
    "        r1_roots = Z_1 * np.exp(1j*theta_1)\n",
    "        r2_roots = Z_2 * np.exp(1j*theta_2)\n",
    "        roots = [r1_roots, np.conjugate(r1_roots), r2_roots, np.conjugate(r2_roots)]\n",
    "\n",
    "        # Convert the roots to zeros, poles, and gain representation\n",
    "        zeros = []\n",
    "        poles = roots\n",
    "        gain = 1.0\n",
    "\n",
    "        # Convert zeros, poles, and gain to filter coefficients\n",
    "        b, a = signal.zpk2tf(zeros, poles, gain)\n",
    "\n",
    "        # Apply the all-pole filter to the input signal\n",
    "        y_arr = signal.lfilter(b, a, s_t_arr)\n",
    "\n",
    "        total_filtered = np.concatenate((total_filtered, y_arr))\n",
    "\n",
    "        normalized_signal = np.zeros_like(y_arr)\n",
    "\n",
    "        for i in range(0, len(y_arr) - window_size + 1, window_size - overlap):\n",
    "            window = y_arr[i:i + window_size]  # Extract a window of the signal\n",
    "            scaling_factor = 1.0 / np.max(np.abs(window))  # Calculate the scaling factor\n",
    "            normalized_signal[i:i + window_size] = window * scaling_factor  # Normalize the window\n",
    "\n",
    "        total_normalized_signal = np.concatenate((total_normalized_signal, normalized_signal))\n",
    "\n",
    "        #     # Enveloped signal \n",
    "\n",
    "        # W_t = (0.42 + 0.5*np.cos(np.pi * t/T) + 0.08*np.cos(2*np.pi * t/T))\n",
    "        W_t = 0.5 * (1 - np.cos(2 * np.pi * t / T))\n",
    "\n",
    "        waveform_filtered_envelope = normalized_signal * W_t\n",
    "\n",
    "        total_envelope = np.concatenate((total_envelope, waveform_filtered_envelope))\n",
    "\n",
    "        phrase_duration += waveform_filtered_envelope.shape[0]/44100\n",
    "        num_repeats +=1\n",
    "\n",
    "    phrase_duration_list.append(phrase_duration)\n",
    "    num_repeats_list.append(num_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies, times, spectrogram = signal.spectrogram(total_envelope, fs=sampling_freq,\n",
    "                                            window='hamming', nperseg=256,\n",
    "                                            noverlap=128, nfft=512)\n",
    "plt.figure()\n",
    "plt.pcolormesh(times, frequencies, spectrogram, cmap='jet')\n",
    "plt.title(f'Spectrogram_of_Song_{song_index}')\n",
    "plt.savefig(f'{folderpath_song}Spectrogram_of_Song.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d4299",
   "metadata": {},
   "source": [
    "### Creating the labels for our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c572b",
   "metadata": {},
   "source": [
    "We have a label per sample, but instead we want a label per pixel in the spectrogram. Because of the Heisenberg Uncertainty Principle, we will lose some temporal resolution because in favor of frequency resolution. Hence, we must find the appropriate mapping between our labels-per-sample and our labels-per-pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1965557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples and pixels\n",
    "num_samples = len(total_envelope)\n",
    "num_pixels = spectrogram.shape[1]\n",
    "\n",
    "# Create an array to store labels per pixel\n",
    "labels_per_pixel = np.zeros(num_pixels)\n",
    "\n",
    "# # Calculate the mapping between samples and pixels\n",
    "overlap = 128\n",
    "window_size = 256\n",
    "samples_per_pixel = (window_size - overlap)\n",
    "mapping = np.arange(0, num_samples - window_size + 1, samples_per_pixel)\n",
    "\n",
    "# Map each label to the corresponding time pixel in the spectrogram using majority voting\n",
    "for i in range(num_pixels):\n",
    "    start_sample = mapping[i]\n",
    "    end_sample = start_sample + samples_per_pixel\n",
    "    labels_in_window = labels_per_sample[start_sample:end_sample]\n",
    "    labels_per_pixel[i] = np.bincount(labels_in_window.astype('int')).argmax()\n",
    "\n",
    "times_and_labels = np.concatenate((times.reshape(times.shape[0],1), labels_per_pixel.reshape(labels_per_pixel.shape[0],1)), axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae3d5d",
   "metadata": {},
   "source": [
    "### Creating data structures that will store our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = {\n",
    "        's': spectrogram,\n",
    "        't': times, \n",
    "        'f':frequencies, \n",
    "        'labels':labels_per_pixel\n",
    "        }\n",
    "\n",
    "np.savez(f'{folderpath_song}synthetic_data.npz', **dat)\n",
    "write(f'{folderpath_song}audio_representation.wav', sampling_freq, total_envelope)\n",
    "\n",
    "\n",
    "num_repeats = np.array(num_repeats_list)\n",
    "num_repeats_songs[song_index,:] = num_repeats\n",
    "\n",
    "syllables = np.array([])\n",
    "for syl_index in np.arange(syllable_phrase_order_w_repeats.shape[0]):\n",
    "    syl = syllable_phrase_order_w_repeats[syl_index]\n",
    "    repeats = num_repeats[syl_index]\n",
    "    repeated_syllable = np.repeat(syl, repeats)\n",
    "    syllables = np.concatenate((syllables, repeated_syllable))\n",
    "\n",
    "syllables = syllables.astype('int')\n",
    "\n",
    "\n",
    "df_dict = {\n",
    "    'Syllable': syllables.tolist(), \n",
    "    'f_0': f_0_vector, \n",
    "    'B' : B_vector,\n",
    "    'phi_0': phi_0_vector, \n",
    "    'delta_phi': delta_phi_vector, \n",
    "    'c': c_vector, \n",
    "    'Z1': Z_1_vector,\n",
    "    'Z2': Z_2_vector, \n",
    "    'theta_1': theta_1_vector, \n",
    "    'theta_2': theta_2_vector,\n",
    "    'T_flattened': T_vector\n",
    "    }\n",
    "\n",
    "np.savez(f'{folderpath_song}acoustic_params_for_song.npz', **df_dict)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(df_dict)\n",
    "\n",
    "# # plt.figure(figsize=(35, 35))\n",
    "# # sns.pairplot(df, hue = 'Syllable')\n",
    "# # # Adjust the layout to prevent clipping\n",
    "# # plt.tight_layout()\n",
    "# # plt.show()\n",
    "\n",
    "grouped_df = df.groupby('Syllable').mean()\n",
    "print(grouped_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d4017",
   "metadata": {},
   "source": [
    "### Visualize the simulated parameter regime for each syllable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e3298",
   "metadata": {},
   "source": [
    "We will perform a UMAP decomposition so that we can easily visualize the parameter regimes for each distinct syllable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07339850",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "X  = df.iloc[:, 1:]\n",
    "X = X.values\n",
    "y = df.Syllable\n",
    "y = y.values\n",
    "embedding = reducer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# plt.scatter(embedding[:,0], embedding[:,1], c=y, cmap='viridis', s=50)\n",
    "\n",
    "categories = y \n",
    "\n",
    "# Create separate scatter plots for each category\n",
    "for category in np.unique(categories):\n",
    "    mask = categories == category\n",
    "    plt.scatter(embedding[mask,0], embedding[mask,1], label=category, s=50)\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.title(f'UMAP Embedding of the Parameter Regimes for Each Syllable for Song_{song_index}')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "plt.savefig(f'{folderpath_song}UMAP_of_song.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f0d3f",
   "metadata": {},
   "source": [
    "### Plot the Phrase Durations across all phrases in our song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97308a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_duration_arr = np.array(phrase_duration_list)\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Create a histogram of the data\n",
    "hist, bins = np.histogram(phrase_duration_arr, bins=10, density=True)\n",
    "\n",
    "# Calculate the density curve using KDE\n",
    "density_curve = gaussian_kde(phrase_duration_arr)\n",
    "\n",
    "# Generate x values for the density curve\n",
    "x = np.linspace(phrase_duration_arr.min(), phrase_duration_arr.max(), 100)\n",
    "\n",
    "# Calculate the y values (density) for the density curve\n",
    "y = density_curve(x)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(phrase_duration_arr, bins=10, density=True, alpha=0.5, label='Histogram')\n",
    "\n",
    "# Plot the density curve\n",
    "plt.plot(x, y, color='red', label='Density Curve')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Phrase Duration')\n",
    "plt.ylabel('Density')\n",
    "plt.title(f'Distribution of Phrase Durations for Song')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "plt.savefig(f'{folderpath_song}Phrase_Durations_of_Song.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082f5a1",
   "metadata": {},
   "source": [
    "## Simulating an arbitrary number of songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f840b282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/Users/ananyakapoor/Dropbox (University of Oregon)/Kapoor_Ananya/01_Projects/01_b_Canary_SSL/Canary_SSL_Repo/Song_0/' already exists.\n",
      "Syllable               0            1            2            3            4  \\\n",
      "f_0          1315.344206  1210.370048  1226.384155  1332.974526  1444.863116   \n",
      "B             472.113210   422.502091   448.876828   466.643952   356.107526   \n",
      "phi_0           2.095279     4.851960     1.131273     5.385145     0.331316   \n",
      "delta_phi       3.193435    -0.691306     3.364514     3.623855     1.080995   \n",
      "c              59.359309    44.447646    49.834525    50.570037    69.592553   \n",
      "Z1              0.884807     0.890643     0.892110     0.902947     0.896163   \n",
      "Z2              0.888383     0.926116     0.885657     0.912463     0.907554   \n",
      "theta_1         1.341379     1.528863     0.672754     0.804046     0.737043   \n",
      "theta_2         1.501432     1.099174     0.961091     1.391042     0.027875   \n",
      "T_flattened     0.399433     0.066466     0.075024     0.069692     0.089437   \n",
      "\n",
      "Syllable               5            6           7            8            9  \n",
      "f_0          1223.499817  1060.099842  986.239379  1032.213616  1353.715585  \n",
      "B             460.195750   455.570267  407.253594   362.896626   476.431755  \n",
      "phi_0           0.044490     1.822100    5.029259     3.724960     5.419814  \n",
      "delta_phi      -3.308910    -0.165608    0.142050     3.926145    -2.325211  \n",
      "c              61.758039    68.599488   65.516556    53.345328    54.621694  \n",
      "Z1              0.884968     0.910892    0.915572     0.922085     0.903297  \n",
      "Z2              0.891422     0.903398    0.915248     0.900065     0.922761  \n",
      "theta_1         0.509724     0.809445    1.455523     0.461230     0.390775  \n",
      "theta_2         0.872265     0.206430    0.335692     0.457993     1.547945  \n",
      "T_flattened     0.062978     0.087646    0.054079     0.067462     0.405038  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AnanyaKapoor/.conda/envs/Canary_Deep_Learning/lib/python3.9/site-packages/sklearn/manifold/_spectral_embedding.py:274: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.signal as signal\n",
    "import sounddevice as sd  \n",
    "from scipy.io.wavfile import write\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import umap\n",
    "import os \n",
    "\n",
    "folderpath = '/Users/ananyakapoor/Dropbox (University of Oregon)/Kapoor_Ananya/01_Projects/01_b_Canary_SSL/Canary_SSL_Repo/'\n",
    "plt.ioff()\n",
    "\n",
    "sampling_freq = 44100\n",
    "\n",
    "num_syllables = 10\n",
    "num_short = 8\n",
    "num_long = 2\n",
    "\n",
    "mean_phi_0 = (np.random.uniform(0, 2*np.pi, num_syllables)).reshape(1, num_syllables)\n",
    "mean_delta_phi = (np.random.uniform(-3*np.pi/2, 3*np.pi/2, num_syllables)).reshape(1, num_syllables) # In radians\n",
    "mean_B = (np.random.uniform(300, 500, num_syllables)).reshape(1, num_syllables) # In Hz\n",
    "mean_c = (np.random.uniform(40, 70, num_syllables)).reshape(1, num_syllables)\n",
    "mean_f_0 = (np.random.uniform(800, 1500, num_syllables)).reshape(1, num_syllables) # In Hz\n",
    "\n",
    "short_durations = np.random.uniform(30/1000, 90/1000, num_short)\n",
    "long_durations = np.random.uniform(200/1000, 500/1000, num_long)\n",
    "# short_repeats = np.random.randint(50, 100, num_short)\n",
    "# long_repeats = np.random.randint(3, 5, num_long)\n",
    "\n",
    "mean_T = np.concatenate((short_durations, long_durations))\n",
    "# num_repeats = np.concatenate((short_repeats, long_repeats))\n",
    "\n",
    "permutation = np.random.permutation(len(mean_T))\n",
    "\n",
    "mean_T = mean_T[permutation]\n",
    "mean_T.shape = (1, num_syllables)\n",
    "# num_repeats = num_repeats[permutation]\n",
    "\n",
    "mean_Z_1 = (np.random.uniform(0.88, 0.93, num_syllables)).reshape(1, num_syllables)\n",
    "mean_Z_2 = (np.random.uniform(0.88, 0.93, num_syllables)).reshape(1, num_syllables)\n",
    "mean_theta_1 = (np.random.uniform(0.01, np.pi/2, num_syllables)).reshape(1, num_syllables)\n",
    "mean_theta_2 = (np.random.uniform(0.01, np.pi/2, num_syllables)).reshape(1, num_syllables)\n",
    "\n",
    "# num_repeats = 50*np.ones((1, num_syllables)) # Simple example\n",
    "\n",
    "mean_matrix = np.concatenate((mean_phi_0, mean_delta_phi, mean_B, mean_c, mean_f_0, mean_T, mean_Z_1, mean_Z_2, mean_theta_1, mean_theta_2), axis = 0)\n",
    "\n",
    "# Let's find a random order of syllable phrases to simulate \n",
    "unique_syllables = np.arange(num_syllables)\n",
    "syllable_phrase_order = unique_syllables.copy()\n",
    "phrase_repeats = 5\n",
    "\n",
    "num_songs = 1\n",
    "\n",
    "# For each song we want to store the following information: \n",
    "    # 1. The phrase order of each song (which will be different for every song)\n",
    "    # 2. The acoustic parameters for each syllable repeat within the song \n",
    "    # 3. The spectrogram with labels \n",
    "    # 4. The audio representation\n",
    "    # 5. The number of repeats per syllable phrase\n",
    "    \n",
    "\n",
    "syllable_phrase_order_songs = np.zeros((num_songs, syllable_phrase_order.shape[0]))\n",
    "num_repeats_songs = np.zeros((num_songs, num_syllables*phrase_repeats))\n",
    "\n",
    "for song_index in np.arange(num_songs):\n",
    "    folderpath_song = f'{folderpath}Song_{song_index}/'\n",
    "    if not os.path.exists(folderpath_song):\n",
    "        # Create the directory\n",
    "        os.makedirs(folderpath_song)\n",
    "        print(f\"Directory '{folderpath_song}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{folderpath_song}' already exists.\")\n",
    "        \n",
    "\n",
    "    np.random.shuffle(syllable_phrase_order) # ex: 0, 2, 1 means that we will simulate syllable 0 first, followed by 2 and then followed by 1\n",
    "    syllable_phrase_order_songs[song_index,:] = syllable_phrase_order\n",
    "    \n",
    "    syllable_phrase_order_w_repeats = np.repeat(syllable_phrase_order, phrase_repeats) # Now add the number of phrase repeats \n",
    "    \n",
    "    \n",
    "\n",
    "    phi_0_vector = []\n",
    "    delta_phi_vector = []\n",
    "    B_vector = []\n",
    "    c_vector = []\n",
    "    f_0_vector = []\n",
    "    T_vector = []\n",
    "    Z_1_vector = []\n",
    "    Z_2_vector = []\n",
    "    theta_1_vector = []\n",
    "    theta_2_vector = []\n",
    "\n",
    "    # Initializing empty arrays that will hold our signal wave, filtered wave, and enveloped wave\n",
    "    \n",
    "    total_signal_wave = np.array([])\n",
    "    total_filtered = np.array([])\n",
    "    total_envelope = np.array([])\n",
    "    total_normalized_signal = np.array([])\n",
    "\n",
    "    labels_per_sample = np.array([])\n",
    "    \n",
    "    # Sample parameters\n",
    "    window_duration_seconds = 0.02  # 40 ms window\n",
    "    window_size = int(sampling_freq * window_duration_seconds)\n",
    "    overlap_fraction = 0.9       # 90 percent overlap           \n",
    "    overlap = int(window_size * overlap_fraction) \n",
    "    \n",
    "    low_frequency_check = 0 \n",
    "    high_frequency_check = 0\n",
    "    \n",
    "    # f_0 = 0\n",
    "    num_repeats_list = []\n",
    "    # Double for loop: one over the syllable phrase and the other over the number of repeats of syllable\n",
    "    phrase_duration_list = []\n",
    "    for syl in syllable_phrase_order_w_repeats:\n",
    "        # mu = mean_matrix[:,syl]\n",
    "        # mean_duration = mu[5]\n",
    "        # num_repeats = np.ceil(2 /mean_duration)\n",
    "        # num_repeats_list.append(num_repeats)\n",
    "            \n",
    "        num_repeats = 0\n",
    "        phrase_duration = 0\n",
    "        \n",
    "        while phrase_duration < 1.4:\n",
    "    \n",
    "            # We are going to ensure that each simulated parameter is within 1% of the mean value for the parameter. This will result in syllables with very little within-syllable variability\n",
    "        \n",
    "            # Draw acoustic parameters with respect to the mean vector corresponding to the syllable we are simulating\n",
    "            mu = mean_matrix[:,syl]\n",
    "            \n",
    "            # Define the desired radius (strictly within 0.05 from the centroid)\n",
    "            radius = 0.025\n",
    "            \n",
    "            # Number of random points to generate\n",
    "            num_points = 1\n",
    "            \n",
    "            # Number of dimensions (size of the centroid array)\n",
    "            num_dimensions = mu.shape[0]\n",
    "            \n",
    "            # Generate random directions (unit vectors) in num_dimensions-dimensional space\n",
    "            random_directions = np.random.randn(num_points, num_dimensions)\n",
    "            random_directions /= np.linalg.norm(random_directions, axis=1)[:, np.newaxis]\n",
    "            \n",
    "            # Generate random distances within the desired radius for each dimension\n",
    "            random_distances = radius * np.random.rand(num_points) ** (1/num_dimensions)\n",
    "            \n",
    "            # Calculate the final random points within the hypersphere\n",
    "            acoustic_params = mu + random_distances[:, np.newaxis] * random_directions\n",
    "            acoustic_params.shape = (10,)\n",
    "    \n",
    "            \n",
    "            # for param in np.arange(10):\n",
    "            #     sim_param = (np.random.uniform(mu[param] - mu[param]*0.05, mu[param]+mu[param]*0.05, 1))\n",
    "            #     acoustic_params = np.concatenate((acoustic_params, sim_param))\n",
    "        \n",
    "            # acoustic_params = np.random.multivariate_normal(mean_matrix[:,syl], covariance_matrix[syl, :, :])\n",
    "            \n",
    "            # tab = np.concatenate((mean_matrix[:,syl].reshape(10,1), acoustic_params.reshape(10,1)), axis = 1)\n",
    "            # if low_frequency_check == 1:\n",
    "            #     f_0 += 50\n",
    "            #     acoustic_params[4] = f_0 \n",
    "            # elif high_frequency_check == 1:\n",
    "            #     f_0 -= 50\n",
    "            #     acoustic_params[4] = f_0 \n",
    "            \n",
    "                \n",
    "            \n",
    "            phi_0 = acoustic_params[0]\n",
    "            phi_0_vector.append(phi_0)\n",
    "            \n",
    "            delta_phi = acoustic_params[1]\n",
    "            delta_phi_vector.append(delta_phi)\n",
    "            \n",
    "            B = acoustic_params[2]\n",
    "            # B_vector.append(B)\n",
    "            \n",
    "            c = acoustic_params[3]\n",
    "            c_vector.append(c)\n",
    "            \n",
    "            f_0 = acoustic_params[4]\n",
    "            # f_0_vector.append(f_0)\n",
    "            \n",
    "            T = acoustic_params[5]\n",
    "            T_vector.append(T)\n",
    "            # print(T)\n",
    "            \n",
    "            Z_1 = acoustic_params[6]\n",
    "            Z_1_vector.append(Z_1)\n",
    "            \n",
    "            Z_2 = acoustic_params[7]\n",
    "            Z_2_vector.append(Z_2)\n",
    "            \n",
    "            theta_1 = acoustic_params[8]\n",
    "            theta_1_vector.append(theta_1)\n",
    "            \n",
    "            theta_2 = acoustic_params[9]\n",
    "            theta_2_vector.append(theta_2)\n",
    "            \n",
    "            # Let's create a table where we have the sampled acoustic parameters plotted against the mean acoustic parameters\n",
    "            tab = np.concatenate((mean_matrix[:,syl].reshape(10,1), acoustic_params.reshape(10,1)), axis = 1)\n",
    "            \n",
    "            num_samples = int((T)*sampling_freq)\n",
    "            t = np.linspace(0, ((T)), num_samples) \n",
    "    \n",
    "            # Calculate the fundamental frequency across time\n",
    "            f = f_0 + B*np.cos(phi_0 + delta_phi*t/T)\n",
    "            \n",
    "            syllable_labels = np.repeat(syl, t.shape[0])\n",
    "            labels_per_sample = np.concatenate((labels_per_sample, syllable_labels))\n",
    "            \n",
    "            \n",
    "            while np.min(f)<700:\n",
    "                low_frequency_check = 1\n",
    "                f_0+=50\n",
    "                B -=20\n",
    "                f = f_0 + B*np.cos(phi_0 + delta_phi*t/T)\n",
    "            \n",
    "            while np.max(f)>3000:\n",
    "                high_frequency_check == 1\n",
    "                f_0-=50\n",
    "                B-=20\n",
    "                f = f_0 + B*np.cos(phi_0 + delta_phi*t/T)\n",
    "            \n",
    "            # if np.min(f)<700:\n",
    "            #     low_frequency_check = 1\n",
    "            #     f_0+=50\n",
    "            #     B-=20\n",
    "            # else:\n",
    "            #     low_frequency_check = 0\n",
    "                \n",
    "            # if np.max(f)>3000:\n",
    "            #     high_frequency_check = 1\n",
    "            #     f_0-=50\n",
    "            #     B-=20\n",
    "            # else:\n",
    "            #     high_frequency_check = 0\n",
    "                \n",
    "            # if (low_frequency_check ==1) or (high_frequency_check == 1):\n",
    "            #     # Recalculate the fundamental frequency across time with the new f_0 and B values\n",
    "            #     f = f_0 + B*np.cos(phi_0 + delta_phi*t/T)\n",
    "                \n",
    "                    \n",
    "            f_0_vector.append(f_0)\n",
    "            B_vector.append(B)\n",
    "            # It's the B*np.cos(phi_0_values + delta_phi_values*t/T) that gives the fundamental frequency its wavy shape. f_0 just shifts it up\n",
    "            \n",
    "            #     # Now let's calculate the harmonics \n",
    "            num_harmonics = 12\n",
    "            theta_arr = np.zeros((num_harmonics, t.shape[0]))\n",
    "            for k in np.arange(num_harmonics):\n",
    "                # val = 2*np.pi*(k+1)*f.reshape(f.shape[0],)\n",
    "                val = 2*np.pi*(k+1)*f_0*t + (2*np.pi*(k+1)*B*T/(delta_phi))*(np.sin((phi_0)+(delta_phi)/T*t) - np.sin((phi_0)))\n",
    "                theta_arr[k, :] = val\n",
    "                \n",
    "            ## coefficients\n",
    "            \n",
    "            A_list = [1]\n",
    "            for k in np.arange(2, (num_harmonics + 1)):\n",
    "                coef = 1/(1+c*2**(k-1))\n",
    "                # coef = 1\n",
    "                A_list.append(coef)\n",
    "                \n",
    "            #     # Raw signal\n",
    "                \n",
    "            s_t_arr = np.zeros_like(t)\n",
    "            \n",
    "            for k in np.arange(len(A_list)):\n",
    "                signal_val = A_list[k]*np.sin(theta_arr[k,:])\n",
    "                s_t_arr += signal_val\n",
    "            \n",
    "            \n",
    "            total_signal_wave = np.concatenate((total_signal_wave, s_t_arr))\n",
    "                \n",
    "            #     # Filtered signal\n",
    "    \n",
    "            r1_roots = Z_1 * np.exp(1j*theta_1)\n",
    "            r2_roots = Z_2 * np.exp(1j*theta_2)\n",
    "            roots = [r1_roots, np.conjugate(r1_roots), r2_roots, np.conjugate(r2_roots)]\n",
    "            \n",
    "            # Convert the roots to zeros, poles, and gain representation\n",
    "            zeros = []\n",
    "            poles = roots\n",
    "            gain = 1.0\n",
    "    \n",
    "            # Convert zeros, poles, and gain to filter coefficients\n",
    "            b, a = signal.zpk2tf(zeros, poles, gain)\n",
    "    \n",
    "            # Apply the all-pole filter to the input signal\n",
    "            y_arr = signal.lfilter(b, a, s_t_arr)\n",
    "    \n",
    "            total_filtered = np.concatenate((total_filtered, y_arr))\n",
    "            \n",
    "            normalized_signal = np.zeros_like(y_arr)\n",
    "    \n",
    "            for i in range(0, len(y_arr) - window_size + 1, window_size - overlap):\n",
    "                window = y_arr[i:i + window_size]  # Extract a window of the signal\n",
    "                scaling_factor = 1.0 / np.max(np.abs(window))  # Calculate the scaling factor\n",
    "                normalized_signal[i:i + window_size] = window * scaling_factor  # Normalize the window\n",
    "    \n",
    "            total_normalized_signal = np.concatenate((total_normalized_signal, normalized_signal))\n",
    "                \n",
    "            #     # Enveloped signal \n",
    "            \n",
    "            # W_t = (0.42 + 0.5*np.cos(np.pi * t/T) + 0.08*np.cos(2*np.pi * t/T))\n",
    "            W_t = 0.5 * (1 - np.cos(2 * np.pi * t / T))\n",
    "                \n",
    "            waveform_filtered_envelope = normalized_signal * W_t\n",
    "            \n",
    "            total_envelope = np.concatenate((total_envelope, waveform_filtered_envelope))\n",
    "            \n",
    "            phrase_duration += waveform_filtered_envelope.shape[0]/44100\n",
    "            num_repeats +=1\n",
    "            \n",
    "        phrase_duration_list.append(phrase_duration)\n",
    "        num_repeats_list.append(num_repeats)\n",
    "        \n",
    "\n",
    "    frequencies, times, spectrogram = signal.spectrogram(total_envelope, fs=sampling_freq,\n",
    "                                                        window='hamming', nperseg=256,\n",
    "                                                        noverlap=128, nfft=512)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.pcolormesh(times, frequencies, spectrogram, cmap='jet')\n",
    "    plt.title(f'Spectrogram_of_Song_{song_index}')\n",
    "    plt.savefig(f'{folderpath_song}Spectrogram_of_Song.png')\n",
    "    \n",
    "    # Calculate the number of samples and pixels\n",
    "    num_samples = len(total_envelope)\n",
    "    num_pixels = spectrogram.shape[1]\n",
    "    \n",
    "    # Create an array to store labels per pixel\n",
    "    labels_per_pixel = np.zeros(num_pixels)\n",
    "    \n",
    "    # # Calculate the mapping between samples and pixels\n",
    "    overlap = 128\n",
    "    window_size = 256\n",
    "    samples_per_pixel = (window_size - overlap)\n",
    "    mapping = np.arange(0, num_samples - window_size + 1, samples_per_pixel)\n",
    "    \n",
    "    # Map each label to the corresponding time pixel in the spectrogram using majority voting\n",
    "    for i in range(num_pixels):\n",
    "        start_sample = mapping[i]\n",
    "        end_sample = start_sample + samples_per_pixel\n",
    "        labels_in_window = labels_per_sample[start_sample:end_sample]\n",
    "        labels_per_pixel[i] = np.bincount(labels_in_window.astype('int')).argmax()\n",
    "    \n",
    "    times_and_labels = np.concatenate((times.reshape(times.shape[0],1), labels_per_pixel.reshape(labels_per_pixel.shape[0],1)), axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dat = {\n",
    "            's': spectrogram,\n",
    "            't': times, \n",
    "            'f':frequencies, \n",
    "            'labels':labels_per_pixel\n",
    "            }\n",
    "    \n",
    "    np.savez(f'{folderpath_song}synthetic_data.npz', **dat)\n",
    "    write(f'{folderpath_song}audio_representation.wav', sampling_freq, total_envelope)\n",
    "    \n",
    "    \n",
    "    num_repeats = np.array(num_repeats_list)\n",
    "    num_repeats_songs[song_index,:] = num_repeats\n",
    "    \n",
    "    syllables = np.array([])\n",
    "    for syl_index in np.arange(syllable_phrase_order_w_repeats.shape[0]):\n",
    "        syl = syllable_phrase_order_w_repeats[syl_index]\n",
    "        repeats = num_repeats[syl_index]\n",
    "        repeated_syllable = np.repeat(syl, repeats)\n",
    "        syllables = np.concatenate((syllables, repeated_syllable))\n",
    "        \n",
    "    syllables = syllables.astype('int')\n",
    "    \n",
    "    \n",
    "    df_dict = {\n",
    "        'Syllable': syllables.tolist(), \n",
    "        'f_0': f_0_vector, \n",
    "        'B' : B_vector,\n",
    "        'phi_0': phi_0_vector, \n",
    "        'delta_phi': delta_phi_vector, \n",
    "        'c': c_vector, \n",
    "        'Z1': Z_1_vector,\n",
    "        'Z2': Z_2_vector, \n",
    "        'theta_1': theta_1_vector, \n",
    "        'theta_2': theta_2_vector,\n",
    "        'T_flattened': T_vector\n",
    "        }\n",
    "    \n",
    "    np.savez(f'{folderpath_song}acoustic_params_for_song.npz', **df_dict)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    \n",
    "    # # plt.figure(figsize=(35, 35))\n",
    "    # # sns.pairplot(df, hue = 'Syllable')\n",
    "    # # # Adjust the layout to prevent clipping\n",
    "    # # plt.tight_layout()\n",
    "    # # plt.show()\n",
    "    \n",
    "    grouped_df = df.groupby('Syllable').mean()\n",
    "    print(grouped_df.T)\n",
    "    \n",
    "    \n",
    "    reducer = umap.UMAP()\n",
    "    X  = df.iloc[:, 1:]\n",
    "    X = X.values\n",
    "    y = df.Syllable\n",
    "    y = y.values\n",
    "    embedding = reducer.fit_transform(X)\n",
    "    \n",
    "    plt.figure()\n",
    "    # plt.scatter(embedding[:,0], embedding[:,1], c=y, cmap='viridis', s=50)\n",
    "    \n",
    "    categories = y \n",
    "    \n",
    "    # Create separate scatter plots for each category\n",
    "    for category in np.unique(categories):\n",
    "        mask = categories == category\n",
    "        plt.scatter(embedding[mask,0], embedding[mask,1], label=category, s=50)\n",
    "    \n",
    "    # Set plot labels and title\n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    plt.title(f'UMAP Embedding of the Parameter Regimes for Each Syllable for Song_{song_index}')\n",
    "    \n",
    "    # Show the legend\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{folderpath_song}UMAP_of_song.png')\n",
    "    \n",
    "    np.save(f'{folderpath_song}UMAP_embedding_of_acoustic_params.npy', embedding)\n",
    "    \n",
    "    \n",
    "    # plt.figure()\n",
    "    # plt.plot(total_envelope)\n",
    "    # plt.show()\n",
    "\n",
    "# # # %% Now I want to plot the phrase durations across all phrases in our song\n",
    "\n",
    "\n",
    "\n",
    "    phrase_duration_arr = np.array(phrase_duration_list)\n",
    "    \n",
    "    from scipy.stats import gaussian_kde\n",
    "    \n",
    "    # Create a histogram of the data\n",
    "    hist, bins = np.histogram(phrase_duration_arr, bins=10, density=True)\n",
    "    \n",
    "    # Calculate the density curve using KDE\n",
    "    density_curve = gaussian_kde(phrase_duration_arr)\n",
    "    \n",
    "    # Generate x values for the density curve\n",
    "    x = np.linspace(phrase_duration_arr.min(), phrase_duration_arr.max(), 100)\n",
    "    \n",
    "    # Calculate the y values (density) for the density curve\n",
    "    y = density_curve(x)\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    # Plot the histogram\n",
    "    plt.hist(phrase_duration_arr, bins=10, density=True, alpha=0.5, label='Histogram')\n",
    "    \n",
    "    # Plot the density curve\n",
    "    plt.plot(x, y, color='red', label='Density Curve')\n",
    "    \n",
    "    # Set plot labels and title\n",
    "    plt.xlabel('Phrase Duration')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'Distribution of Phrase Durations for Song')\n",
    "    \n",
    "    # Show the legend\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{folderpath_song}Phrase_Durations_of_Song.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa36581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
