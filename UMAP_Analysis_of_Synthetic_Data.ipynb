{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d453769",
   "metadata": {},
   "source": [
    "# UMAP Analysis of Synthetic Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b64bc453",
   "metadata": {},
   "source": [
    "This notebook largely borrows code from my \"Rotation_Gardner\" repository. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b7e807e",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9aa8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.signal as signal\n",
    "# import sounddevice as sd  \n",
    "from scipy.io.wavfile import write\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import umap\n",
    "import os \n",
    "from bokeh.plotting import figure, show, output_file, save\n",
    "from bokeh.models import HoverTool, ColumnDataSource\n",
    "import seaborn as sns\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9ea7f2e",
   "metadata": {},
   "source": [
    "Load in the spectrogram-specific data for a particular song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "389d4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters we set\n",
    "num_spec = 10\n",
    "window_size = 100\n",
    "stride = 10\n",
    "\n",
    "\n",
    "phrase_repeats = 5\n",
    "num_songs = 10\n",
    "radius_value = 0.01\n",
    "num_syllables = 10\n",
    "\n",
    "folderpath = '/home/akapoor/Dropbox (University of Oregon)/Kapoor_Ananya/01_Projects/01_b_Canary_SSL/Canary_SSL_Repo/'\n",
    "songpath = f'{folderpath}num_songs_{num_songs}_num_syllables_{num_syllables}_phrase_repeats_{phrase_repeats}_radius_{radius_value}/'\n",
    "\n",
    "# For each spectrogram we will extract\n",
    "# 1. Each timepoint's syllable label\n",
    "# 2. The spectrogram itself\n",
    "stacked_labels = [] \n",
    "stacked_specs = []\n",
    "spectrogram_id = [] \n",
    "\n",
    "all_songs_data = [element for element in os.listdir(songpath)  if 'Song' in element] \n",
    "all_songs_data.sort()\n",
    "all_songs_data = [f'{songpath}{element}' for element in all_songs_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17446afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(num_spec):\n",
    "    folderpath_song = all_songs_data[i]\n",
    "    \n",
    "\n",
    "    # Extract the data within the numpy file. We will use this to create the spectrogram\n",
    "    dat = np.load(f'{folderpath_song}/synthetic_data.npz')\n",
    "    spec = dat['s']\n",
    "    times = dat['t']\n",
    "    frequencies = dat['f']\n",
    "    labels = dat['labels']\n",
    "    labels.shape = (1, labels.shape[0])\n",
    "    labels = labels.T\n",
    "\n",
    "    song_id = np.repeat(i, labels.shape[0])\n",
    "\n",
    "\n",
    "    # Let's get rid of higher order frequencies\n",
    "    mask = (frequencies<4000)&(frequencies>600)\n",
    "    masked_frequencies = frequencies[mask]\n",
    "\n",
    "    subsetted_spec = spec[mask.reshape(mask.shape[0],),:]\n",
    "\n",
    "    stacked_labels.append(labels)\n",
    "    stacked_specs.append(subsetted_spec)\n",
    "    spectrogram_id.append(song_id)\n",
    "        \n",
    "stacked_specs = np.concatenate((stacked_specs), axis = 1)\n",
    "stacked_labels = np.concatenate((stacked_labels), axis = 0)\n",
    "spectrogram_id = np.concatenate((spectrogram_id), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c06e89b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of unique categories (syllable labels)\n",
    "unique_categories = np.unique(stacked_labels)\n",
    "\n",
    "# Create a dictionary that maps categories to random colors\n",
    "category_colors = {category: np.random.rand(3,) for category in unique_categories}\n",
    "\n",
    "spec_for_analysis = stacked_specs.T\n",
    "window_labels_arr = []\n",
    "embedding_arr = []\n",
    "# Find the exact sampling frequency (the time in miliseconds between one pixel [timepoint] and another pixel)\n",
    "dx = np.diff(times)[0]\n",
    "\n",
    "# We will now extract each mini-spectrogram from the full spectrogram\n",
    "stacked_windows = []\n",
    "# Find the syllable labels for each mini-spectrogram\n",
    "stacked_labels_for_window = []\n",
    "# Find the mini-spectrograms onset and ending times \n",
    "stacked_window_times = []\n",
    "\n",
    "# The below for-loop will find each mini-spectrogram (window) and populate the empty lists we defined above.\n",
    "for i in range(0, spec_for_analysis.shape[0] - window_size + 1, stride):\n",
    "    # Find the window\n",
    "    window = spec_for_analysis[i:i + window_size, :]\n",
    "    # Get the window onset and ending times\n",
    "    window_times = dx*np.arange(i, i + window_size)\n",
    "    # We will flatten the window to be a 1D vector\n",
    "    window = window.reshape(1, window.shape[0]*window.shape[1])\n",
    "    # Extract the syllable labels for the window\n",
    "    labels_for_window = stacked_labels[i:i+window_size, :]\n",
    "    # Reshape the syllable labels for the window into a 1D array\n",
    "    labels_for_window = labels_for_window.reshape(1, labels_for_window.shape[0]*labels_for_window.shape[1])\n",
    "    # Populate the empty lists defined above\n",
    "    stacked_windows.append(window)\n",
    "    stacked_labels_for_window.append(labels_for_window)\n",
    "    stacked_window_times.append(window_times)\n",
    "\n",
    "# Convert the populated lists into a stacked numpy array\n",
    "stacked_windows = np.stack(stacked_windows, axis = 0)\n",
    "stacked_windows = np.squeeze(stacked_windows)\n",
    "\n",
    "stacked_labels_for_window = np.stack(stacked_labels_for_window, axis = 0)\n",
    "stacked_labels_for_window = np.squeeze(stacked_labels_for_window)\n",
    "\n",
    "stacked_window_times = np.stack(stacked_window_times, axis = 0)\n",
    "\n",
    "# For each mini-spectrogram, find the average color across all unique syllables\n",
    "mean_colors_per_minispec = np.zeros((stacked_labels_for_window.shape[0], 3))\n",
    "for i in np.arange(stacked_labels_for_window.shape[0]):\n",
    "    list_of_colors_for_row = [category_colors[x] for x in stacked_labels_for_window[i,:]]\n",
    "    all_colors_in_minispec = np.array(list_of_colors_for_row)\n",
    "    mean_color = np.mean(all_colors_in_minispec, axis = 0)\n",
    "    mean_colors_per_minispec[i,:] = mean_color"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "768c04a1",
   "metadata": {},
   "source": [
    "Stack the spectrogram slices, the onset times, and the frequencies array. Create a unique color for each syllable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "441a2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save all the numpy arrays\n",
    "np.save(songpath+'stacked_windows.npy', stacked_windows)\n",
    "np.save(songpath+'labels_for_window.npy', stacked_labels_for_window)\n",
    "np.save(songpath+'masked_frequencies_lowthresh_600_highthresh_4000.npy', masked_frequencies)\n",
    "np.save(songpath+'stacked_window_times.npy', stacked_window_times)\n",
    "np.save(songpath+'mean_colors_per_minispec.npy', mean_colors_per_minispec)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c1c97ff",
   "metadata": {},
   "source": [
    "## Perform a UMAP decomposition on our stacked spectrogram slice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a25ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a UMAP embedding on the dataset of mini-spectrograms\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(stacked_windows)\n",
    "np.save(songpath+'UMAP_Embedding_of_spec.npy', embedding)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49449725",
   "metadata": {},
   "source": [
    "### Bokeh Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a900749c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of 2501\n",
      "Iteration 10 of 2501\n",
      "Iteration 20 of 2501\n",
      "Iteration 30 of 2501\n",
      "Iteration 40 of 2501\n",
      "Iteration 50 of 2501\n",
      "Iteration 60 of 2501\n",
      "Iteration 70 of 2501\n",
      "Iteration 80 of 2501\n",
      "Iteration 90 of 2501\n",
      "Iteration 100 of 2501\n",
      "Iteration 110 of 2501\n",
      "Iteration 120 of 2501\n",
      "Iteration 130 of 2501\n",
      "Iteration 140 of 2501\n",
      "Iteration 150 of 2501\n",
      "Iteration 160 of 2501\n",
      "Iteration 170 of 2501\n",
      "Iteration 180 of 2501\n",
      "Iteration 190 of 2501\n",
      "Iteration 200 of 2501\n",
      "Iteration 210 of 2501\n",
      "Iteration 220 of 2501\n",
      "Iteration 230 of 2501\n",
      "Iteration 240 of 2501\n",
      "Iteration 250 of 2501\n",
      "Iteration 260 of 2501\n",
      "Iteration 270 of 2501\n",
      "Iteration 280 of 2501\n",
      "Iteration 290 of 2501\n",
      "Iteration 300 of 2501\n",
      "Iteration 310 of 2501\n",
      "Iteration 320 of 2501\n",
      "Iteration 330 of 2501\n",
      "Iteration 340 of 2501\n",
      "Iteration 350 of 2501\n",
      "Iteration 360 of 2501\n",
      "Iteration 370 of 2501\n",
      "Iteration 380 of 2501\n",
      "Iteration 390 of 2501\n",
      "Iteration 400 of 2501\n",
      "Iteration 410 of 2501\n",
      "Iteration 420 of 2501\n",
      "Iteration 430 of 2501\n",
      "Iteration 440 of 2501\n",
      "Iteration 450 of 2501\n",
      "Iteration 460 of 2501\n",
      "Iteration 470 of 2501\n",
      "Iteration 480 of 2501\n",
      "Iteration 490 of 2501\n",
      "Iteration 500 of 2501\n",
      "Iteration 510 of 2501\n",
      "Iteration 520 of 2501\n",
      "Iteration 530 of 2501\n",
      "Iteration 540 of 2501\n",
      "Iteration 550 of 2501\n",
      "Iteration 560 of 2501\n",
      "Iteration 570 of 2501\n",
      "Iteration 580 of 2501\n",
      "Iteration 590 of 2501\n",
      "Iteration 600 of 2501\n",
      "Iteration 610 of 2501\n",
      "Iteration 620 of 2501\n",
      "Iteration 630 of 2501\n",
      "Iteration 640 of 2501\n",
      "Iteration 650 of 2501\n",
      "Iteration 660 of 2501\n",
      "Iteration 670 of 2501\n",
      "Iteration 680 of 2501\n",
      "Iteration 690 of 2501\n",
      "Iteration 700 of 2501\n",
      "Iteration 710 of 2501\n",
      "Iteration 720 of 2501\n",
      "Iteration 730 of 2501\n",
      "Iteration 740 of 2501\n",
      "Iteration 750 of 2501\n",
      "Iteration 760 of 2501\n",
      "Iteration 770 of 2501\n",
      "Iteration 780 of 2501\n",
      "Iteration 790 of 2501\n",
      "Iteration 800 of 2501\n",
      "Iteration 810 of 2501\n",
      "Iteration 820 of 2501\n",
      "Iteration 830 of 2501\n",
      "Iteration 840 of 2501\n",
      "Iteration 850 of 2501\n",
      "Iteration 860 of 2501\n",
      "Iteration 870 of 2501\n",
      "Iteration 880 of 2501\n",
      "Iteration 890 of 2501\n",
      "Iteration 900 of 2501\n",
      "Iteration 910 of 2501\n",
      "Iteration 920 of 2501\n",
      "Iteration 930 of 2501\n",
      "Iteration 940 of 2501\n",
      "Iteration 950 of 2501\n",
      "Iteration 960 of 2501\n",
      "Iteration 970 of 2501\n",
      "Iteration 980 of 2501\n",
      "Iteration 990 of 2501\n",
      "Iteration 1000 of 2501\n",
      "Iteration 1010 of 2501\n",
      "Iteration 1020 of 2501\n",
      "Iteration 1030 of 2501\n",
      "Iteration 1040 of 2501\n",
      "Iteration 1050 of 2501\n",
      "Iteration 1060 of 2501\n",
      "Iteration 1070 of 2501\n",
      "Iteration 1080 of 2501\n",
      "Iteration 1090 of 2501\n",
      "Iteration 1100 of 2501\n",
      "Iteration 1110 of 2501\n",
      "Iteration 1120 of 2501\n",
      "Iteration 1130 of 2501\n",
      "Iteration 1140 of 2501\n",
      "Iteration 1150 of 2501\n",
      "Iteration 1160 of 2501\n",
      "Iteration 1170 of 2501\n",
      "Iteration 1180 of 2501\n",
      "Iteration 1190 of 2501\n",
      "Iteration 1200 of 2501\n",
      "Iteration 1210 of 2501\n",
      "Iteration 1220 of 2501\n",
      "Iteration 1230 of 2501\n",
      "Iteration 1240 of 2501\n",
      "Iteration 1250 of 2501\n",
      "Iteration 1260 of 2501\n",
      "Iteration 1270 of 2501\n",
      "Iteration 1280 of 2501\n",
      "Iteration 1290 of 2501\n",
      "Iteration 1300 of 2501\n",
      "Iteration 1310 of 2501\n",
      "Iteration 1320 of 2501\n",
      "Iteration 1330 of 2501\n",
      "Iteration 1340 of 2501\n",
      "Iteration 1350 of 2501\n",
      "Iteration 1360 of 2501\n",
      "Iteration 1370 of 2501\n",
      "Iteration 1380 of 2501\n",
      "Iteration 1390 of 2501\n",
      "Iteration 1400 of 2501\n",
      "Iteration 1410 of 2501\n",
      "Iteration 1420 of 2501\n",
      "Iteration 1430 of 2501\n",
      "Iteration 1440 of 2501\n",
      "Iteration 1450 of 2501\n",
      "Iteration 1460 of 2501\n",
      "Iteration 1470 of 2501\n",
      "Iteration 1480 of 2501\n",
      "Iteration 1490 of 2501\n",
      "Iteration 1500 of 2501\n",
      "Iteration 1510 of 2501\n",
      "Iteration 1520 of 2501\n",
      "Iteration 1530 of 2501\n",
      "Iteration 1540 of 2501\n",
      "Iteration 1550 of 2501\n",
      "Iteration 1560 of 2501\n",
      "Iteration 1570 of 2501\n",
      "Iteration 1580 of 2501\n",
      "Iteration 1590 of 2501\n",
      "Iteration 1600 of 2501\n",
      "Iteration 1610 of 2501\n",
      "Iteration 1620 of 2501\n",
      "Iteration 1630 of 2501\n",
      "Iteration 1640 of 2501\n",
      "Iteration 1650 of 2501\n",
      "Iteration 1660 of 2501\n",
      "Iteration 1670 of 2501\n",
      "Iteration 1680 of 2501\n",
      "Iteration 1690 of 2501\n",
      "Iteration 1700 of 2501\n",
      "Iteration 1710 of 2501\n",
      "Iteration 1720 of 2501\n",
      "Iteration 1730 of 2501\n",
      "Iteration 1740 of 2501\n",
      "Iteration 1750 of 2501\n",
      "Iteration 1760 of 2501\n",
      "Iteration 1770 of 2501\n",
      "Iteration 1780 of 2501\n",
      "Iteration 1790 of 2501\n",
      "Iteration 1800 of 2501\n",
      "Iteration 1810 of 2501\n",
      "Iteration 1820 of 2501\n",
      "Iteration 1830 of 2501\n",
      "Iteration 1840 of 2501\n",
      "Iteration 1850 of 2501\n",
      "Iteration 1860 of 2501\n",
      "Iteration 1870 of 2501\n",
      "Iteration 1880 of 2501\n",
      "Iteration 1890 of 2501\n",
      "Iteration 1900 of 2501\n",
      "Iteration 1910 of 2501\n",
      "Iteration 1920 of 2501\n",
      "Iteration 1930 of 2501\n",
      "Iteration 1940 of 2501\n",
      "Iteration 1950 of 2501\n",
      "Iteration 1960 of 2501\n",
      "Iteration 1970 of 2501\n",
      "Iteration 1980 of 2501\n",
      "Iteration 1990 of 2501\n",
      "Iteration 2000 of 2501\n",
      "Iteration 2010 of 2501\n",
      "Iteration 2020 of 2501\n",
      "Iteration 2030 of 2501\n",
      "Iteration 2040 of 2501\n",
      "Iteration 2050 of 2501\n",
      "Iteration 2060 of 2501\n",
      "Iteration 2070 of 2501\n",
      "Iteration 2080 of 2501\n",
      "Iteration 2090 of 2501\n",
      "Iteration 2100 of 2501\n",
      "Iteration 2110 of 2501\n",
      "Iteration 2120 of 2501\n",
      "Iteration 2130 of 2501\n",
      "Iteration 2140 of 2501\n",
      "Iteration 2150 of 2501\n",
      "Iteration 2160 of 2501\n",
      "Iteration 2170 of 2501\n",
      "Iteration 2180 of 2501\n",
      "Iteration 2190 of 2501\n",
      "Iteration 2200 of 2501\n",
      "Iteration 2210 of 2501\n",
      "Iteration 2220 of 2501\n",
      "Iteration 2230 of 2501\n",
      "Iteration 2240 of 2501\n",
      "Iteration 2250 of 2501\n",
      "Iteration 2260 of 2501\n",
      "Iteration 2270 of 2501\n",
      "Iteration 2280 of 2501\n",
      "Iteration 2290 of 2501\n",
      "Iteration 2300 of 2501\n",
      "Iteration 2310 of 2501\n",
      "Iteration 2320 of 2501\n",
      "Iteration 2330 of 2501\n",
      "Iteration 2340 of 2501\n",
      "Iteration 2350 of 2501\n",
      "Iteration 2360 of 2501\n",
      "Iteration 2370 of 2501\n",
      "Iteration 2380 of 2501\n",
      "Iteration 2390 of 2501\n",
      "Iteration 2400 of 2501\n",
      "Iteration 2410 of 2501\n",
      "Iteration 2420 of 2501\n",
      "Iteration 2430 of 2501\n",
      "Iteration 2440 of 2501\n",
      "Iteration 2450 of 2501\n",
      "Iteration 2460 of 2501\n",
      "Iteration 2470 of 2501\n",
      "Iteration 2480 of 2501\n",
      "Iteration 2490 of 2501\n",
      "Iteration 2500 of 2501\n"
     ]
    }
   ],
   "source": [
    "# The below function will save an image for each mini-spectrogram. This will be used for understanding the UMAP plot.\n",
    "def embeddable_image(data, window_times, iteration_number):\n",
    "    \n",
    "    data.shape = (window_size, int(data.shape[0]/window_size))\n",
    "    data = data.T \n",
    "    window_times = window_times.reshape(1, window_times.shape[0])\n",
    "    plt.pcolormesh(window_times, masked_frequencies, data, cmap='jet')\n",
    "    # let's save the plt colormesh as an image.\n",
    "    plt.savefig(folderpath_song+'/Plots/Window_Plots/'+f'Window_{iteration_number}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "for i in np.arange(stacked_windows.shape[0]):\n",
    "    if i%10 == 0:\n",
    "        print(f'Iteration {i} of {stacked_windows.shape[0]}')\n",
    "    data = stacked_windows[i,:]\n",
    "    window_times = stacked_window_times[i,:]\n",
    "    embeddable_image(data, window_times, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c53f13e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('colors', 25445), ('image', 0), ('x', 25445), ('y', 25445)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/akapoor/Dropbox (University of Oregon)/Kapoor_Ananya/01_Projects/01_b_Canary_SSL/Canary_SSL_Repo/num_songs_10_num_syllables_10_phrase_repeats_5_radius_0.01/Plots/umap.html'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify an HTML file to save the Bokeh image to.\n",
    "output_file(filename=f'{songpath}Plots/umap.html')\n",
    "\n",
    "# Convert the UMAP embedding to a Pandas Dataframe\n",
    "spec_df = pd.DataFrame(embedding, columns=('x', 'y'))\n",
    "\n",
    "\n",
    "# Create a ColumnDataSource from the data. This contains the UMAP embedding components and the mean colors per mini-spectrogram\n",
    "source = ColumnDataSource(data=dict(x = embedding[:,0], y = embedding[:,1], colors=mean_colors_per_minispec))\n",
    "\n",
    "\n",
    "# Create a figure and add a scatter plot\n",
    "p = figure(width=800, height=600, tools=('pan, box_zoom, hover, reset'))\n",
    "p.scatter(x='x', y='y', size = 7, color = 'colors', source=source)\n",
    "\n",
    "hover = p.select(dict(type=HoverTool))\n",
    "hover.tooltips = \"\"\"\n",
    "    <div>\n",
    "        <h3>@x, @y</h3>\n",
    "        <div>\n",
    "            <img\n",
    "                src=\"@image\" height=\"100\" alt=\"@image\" width=\"100\"\n",
    "                style=\"float: left; margin: 0px 15px 15px 0px;\"\n",
    "                border=\"2\"\n",
    "            ></img>\n",
    "        </div>\n",
    "    </div>\n",
    "\"\"\"\n",
    "\n",
    "p.add_tools(HoverTool(tooltips=\"\"\"\n",
    "\"\"\"))\n",
    "\n",
    "\n",
    "# Set the image path for each data point\n",
    "source.data['image'] = []\n",
    "for i in np.arange(spec_df.shape[0]):\n",
    "    source.data['image'].append(f'{songpath}/Plots/Window_Plots/Window_{i}.png')\n",
    "\n",
    "show(p)\n",
    "\n",
    "save(p)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92c9155d",
   "metadata": {},
   "source": [
    "## UMAP on Acoustic Parameters across all songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "869279e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_params_all_songs = np.empty((0, 11))\n",
    "# Create a list to store column vectors\n",
    "acoustic_params_columns = []\n",
    "for song_index in np.arange(len(all_songs_data)):\n",
    "    acoustic_params_dat = np.load(f'{all_songs_data[song_index]}/acoustic_params_for_song.npz')\n",
    "    # Create a list to store column vectors\n",
    "    acoustic_params_columns = []\n",
    "    for key in acoustic_params_dat.keys():\n",
    "        array = acoustic_params_dat[key]\n",
    "        column_vector = array.reshape(-1, 1)\n",
    "        acoustic_params_columns.append(column_vector)\n",
    "    # Stack the column vectors horizontally to create the final array\n",
    "    acoustic_params_arr = np.hstack(acoustic_params_columns)\n",
    "    acoustic_params_all_songs = np.concatenate((acoustic_params_all_songs, acoustic_params_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5c968d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akapoor/ENTER/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:274: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "X  = acoustic_params_all_songs[:,1::]\n",
    "y = acoustic_params_all_songs[:,0]\n",
    "embedding = reducer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f7b12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_per_syllable_category = np.zeros((y.shape[0], 3))\n",
    "\n",
    "for i in np.arange(y.shape[0]):\n",
    "    syllable_label = y[i]\n",
    "    colors_per_syllable_category[i,:] = category_colors[syllable_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8ef7a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41269434, 0.80453025, 0.25652987],\n",
       "       [0.41269434, 0.80453025, 0.25652987],\n",
       "       [0.41269434, 0.80453025, 0.25652987],\n",
       "       ...,\n",
       "       [0.47468595, 0.73589672, 0.75901919],\n",
       "       [0.47468595, 0.73589672, 0.75901919],\n",
       "       [0.47468595, 0.73589672, 0.75901919]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors_per_syllable_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ee29e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/akapoor/Dropbox (University of Oregon)/Kapoor_Ananya/01_Projects/01_b_Canary_SSL/Canary_SSL_Repo/num_songs_10_num_syllables_10_phrase_repeats_5_radius_0.01/Plots/umap_on_acoustic_params.html'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify an HTML file to save the Bokeh image to.\n",
    "output_file(filename=f'{songpath}Plots/umap_on_acoustic_params.html')\n",
    "\n",
    "# Convert the UMAP embedding to a Pandas Dataframe\n",
    "spec_df = pd.DataFrame(embedding, columns=('x', 'y'))\n",
    "\n",
    "\n",
    "# Create a ColumnDataSource from the data. This contains the UMAP embedding components and the mean colors per mini-spectrogram\n",
    "source = ColumnDataSource(data=dict(x = embedding[:,0], y = embedding[:,1], colors=colors_per_syllable_category))\n",
    "\n",
    "\n",
    "# Create a figure and add a scatter plot\n",
    "p = figure(width=800, height=600, tools=('pan, box_zoom, hover, reset'))\n",
    "p.scatter(x='x', y='y', size = 7, color = 'colors', source=source)\n",
    "\n",
    "hover = p.select(dict(type=HoverTool))\n",
    "hover.tooltips = \"\"\"\n",
    "    <div>\n",
    "        <h3>@x, @y</h3>\n",
    "        <div>\n",
    "            <img\n",
    "                src=\"@image\" height=\"100\" alt=\"@image\" width=\"100\"\n",
    "                style=\"float: left; margin: 0px 15px 15px 0px;\"\n",
    "                border=\"2\"\n",
    "            ></img>\n",
    "        </div>\n",
    "    </div>\n",
    "\"\"\"\n",
    "\n",
    "p.add_tools(HoverTool(tooltips=\"\"\"\n",
    "\"\"\"))\n",
    "\n",
    "show(p)\n",
    "\n",
    "save(p)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48b4c8c1",
   "metadata": {},
   "source": [
    "## Preliminary Modeling to show proof-of-concept for contrastive learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00e5b2c3",
   "metadata": {},
   "source": [
    "For contrastive learning to work well we need to ensure that similar syllables are concentrated together. This will allow us to easily pick positive and negative samples for a first-pass contrastive learning approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b12898c4",
   "metadata": {},
   "source": [
    "We had been using HDBSCAN before but we should start off even simpler at first -- a nearest class center classifier and a support vector classifier. This will ensure that high clustering performance is coming from an informative embedding rather than a powerful clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2b52506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# %% Implementation of the NCC classifier \n",
    "\n",
    "actual_labels = np.max(stacked_labels_for_window, axis = 1)\n",
    "\n",
    "unique_labels = np.unique(actual_labels)\n",
    "\n",
    "avg_representation = np.zeros((unique_labels.shape[0], 2)) # 2nd dimension is UMAP embedding size\n",
    "\n",
    "for lab in unique_labels:\n",
    "    lab = int(lab)\n",
    "    embedding_rows = np.where(actual_labels == lab)\n",
    "    embedding_subset = np.squeeze(embedding[embedding_rows, :])\n",
    "    avg_representation[lab, :] = np.mean(embedding_subset, axis = 0)\n",
    "    \n",
    "pred_labels = []\n",
    "for i in np.arange(embedding.shape[0]):\n",
    "    dist_metric = np.sum((embedding[i,:] - avg_representation)**2, axis = 1)\n",
    "    pred_labels.append(np.argmin(dist_metric))\n",
    "    \n",
    "\n",
    "acc_value = np.mean(actual_labels == pred_labels)\n",
    "\n",
    "# This shows that the representations of syllables form centroid like geometry\n",
    "# in representation space. \n",
    "\n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "\n",
    "\n",
    "v_measure_score(actual_labels, np.array(pred_labels))\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an instance of SVC with a linear kernel\n",
    "svc_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svc_classifier.fit(embedding, actual_labels)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svc_classifier.predict(embedding)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(actual_labels, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4058385",
   "metadata": {},
   "source": [
    "We have near perfect accuracy -- makes sense because this is a toy dataset. The next steps will be to use the UMAP decomposition for contrastive learning + neural networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
